{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejaswini16256/30-Days-6-Companies/blob/main/final_modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Function to extract dataset from zip file\n",
        "def extract_dataset(zip_path, extract_to=\"dataset\"):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    return os.path.join(extract_to, \"2DSagittal\")\n",
        "\n",
        "# Example usage\n",
        "zip_path = \"/content/2DSagittal.zip\"\n",
        "dataset_dir = extract_dataset(zip_path)"
      ],
      "metadata": {
        "id": "q4n5_Gm6lUrC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "d321f883-3d37-47f9-e53a-90b98332e90a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/2DSagittal.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3460261674.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mzip_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/2DSagittal.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdataset_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3460261674.py\u001b[0m in \u001b[0;36mextract_dataset\u001b[0;34m(zip_path, extract_to)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Function to extract dataset from zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2DSagittal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/2DSagittal.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdOq8K0KlAlp",
        "outputId": "2cf28c71-54e9-47a1-9e93-8c9650309211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: [Errno 2] No such file or directory: 'dataset/2DSagittal'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from keras.applications import DenseNet121\n",
        "from keras.applications.densenet import preprocess_input\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from imblearn.combine import SMOTETomek\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Skull Stripping Function\n",
        "def skull_stripping(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    kernel = np.ones((5,5), np.uint8)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "    brain = cv2.bitwise_and(image, image, mask=mask)\n",
        "    return brain\n",
        "\n",
        "# Median Filtering Function\n",
        "def apply_median_filter(image):\n",
        "    return cv2.medianBlur(image, 5)\n",
        "\n",
        "# Preprocess Images\n",
        "def preprocess_images(img_dir, target_size=(224, 224)):\n",
        "    images, labels = [], []\n",
        "    class_names = sorted(os.listdir(img_dir))\n",
        "    for label, class_name in enumerate(class_names):\n",
        "        class_path = os.path.join(img_dir, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "            try:\n",
        "                img = cv2.imread(img_path)\n",
        "                img = cv2.resize(img, target_size)\n",
        "                img = skull_stripping(img)\n",
        "                img = apply_median_filter(img)\n",
        "                img = img_to_array(img)\n",
        "                img = preprocess_input(img)\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: {e}. Skipping {img_path}.\")\n",
        "    if len(images) == 0:\n",
        "        raise ValueError(\"No valid images found in the dataset.\")\n",
        "    return np.array(images), np.array(labels), class_names\n",
        "\n",
        "# Balance Dataset\n",
        "def balance_data(X, y):\n",
        "    smote_tomek = SMOTETomek(random_state=42)\n",
        "    X_resampled, y_resampled = smote_tomek.fit_resample(X.reshape(X.shape[0], -1), y)\n",
        "    X_resampled = X_resampled.reshape(-1, 224, 224, 3)\n",
        "    return X_resampled, y_resampled\n",
        "\n",
        "# Fine-tune DenseNet121\n",
        "def fine_tune_densenet(num_classes):\n",
        "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    for layer in base_model.layers[-33:]:\n",
        "        layer.trainable = True\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(512)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('mish')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=output_layer)\n",
        "    return model\n",
        "\n",
        "# Hyperparameter tuning for SVM model\n",
        "def tune_svm(X_train, y_train):\n",
        "    param_grid = {'C': [0.1, 1, 10], 'kernel': ['rbf', 'linear'], 'gamma': ['scale', 'auto']}\n",
        "    svm = SVC(probability=True)\n",
        "    grid_search = GridSearchCV(svm, param_grid, cv=3, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        images, labels, class_names = preprocess_images('dataset/2DSagittal')\n",
        "        images, labels = balance_data(images, labels)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, stratify=labels, random_state=42)\n",
        "\n",
        "        model = fine_tune_densenet(num_classes=len(class_names))\n",
        "        model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        model.fit(X_train, to_categorical(y_train), epochs=15, batch_size=32, validation_data=(X_test, to_categorical(y_test)))\n",
        "\n",
        "        feature_extractor = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
        "        X_train_feats = feature_extractor.predict(X_train)\n",
        "        X_test_feats = feature_extractor.predict(X_test)\n",
        "\n",
        "        best_svm = tune_svm(X_train_feats, y_train)\n",
        "        y_pred = best_svm.predict(X_test_feats)\n",
        "\n",
        "        print(\"\\nSVM Model Results:\")\n",
        "        print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "        print(confusion_matrix(y_test, y_pred))\n",
        "        print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn scikit-learn keras matplotlib seaborn tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhvWgXOQbP_Q",
        "outputId": "43612428-47b0-41f3-aa65-2c107f2cd7f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras) (0.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras) (25.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report, roc_auc_score,\n",
        "                             f1_score, roc_curve)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.inspection import permutation_importance\n",
        "from keras.applications import DenseNet121\n",
        "from keras.applications.densenet import preprocess_input\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Activation, Conv2D, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from imblearn.combine import SMOTETomek\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Skull Stripping Function\n",
        "def skull_stripping(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    kernel = np.ones((5,5), np.uint8)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "    return cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "# Median Filtering Function\n",
        "def apply_median_filter(image):\n",
        "    return cv2.medianBlur(image, 5)\n",
        "\n",
        "# Preprocess Images\n",
        "def preprocess_images(img_dir, target_size=(224, 224), do_preprocessing=True):\n",
        "    images, labels = [], []\n",
        "    class_names = sorted(os.listdir(img_dir))\n",
        "    for label, class_name in enumerate(class_names):\n",
        "        class_path = os.path.join(img_dir, class_name)\n",
        "        if not os.path.isdir(class_path): continue\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "            try:\n",
        "                img = cv2.imread(img_path)\n",
        "                img = cv2.resize(img, target_size)\n",
        "                if do_preprocessing:\n",
        "                    img = skull_stripping(img)\n",
        "                    img = apply_median_filter(img)\n",
        "                img = img_to_array(img)\n",
        "                img = preprocess_input(img)\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: {e} -> Skipping {img_path}\")\n",
        "    return np.array(images), np.array(labels), class_names\n",
        "\n",
        "# Balance Dataset\n",
        "def balance_data(X, y):\n",
        "    smote_tomek = SMOTETomek(random_state=42)\n",
        "    X_res, y_res = smote_tomek.fit_resample(X.reshape(X.shape[0], -1), y)\n",
        "    return X_res.reshape(-1, 224, 224, 3), y_res\n",
        "\n",
        "# DenseNet121 Model\n",
        "def fine_tune_densenet(num_classes):\n",
        "    base = DenseNet121(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "    for layer in base.layers[-33:]:\n",
        "        layer.trainable = True\n",
        "    x = GlobalAveragePooling2D()(base.output)\n",
        "    x = Dense(512)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    out = Dense(num_classes, activation='softmax')(x)\n",
        "    return Model(inputs=base.input, outputs=out)\n",
        "\n",
        "# Simple CNN baseline\n",
        "def simple_cnn(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(64, (3,3), activation='relu'),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# SVM Hyperparameter Tuning\n",
        "def tune_svm(X_train, y_train):\n",
        "    param_grid = {'C':[0.1, 1, 10], 'kernel':['rbf'], 'gamma':['scale', 'auto']}\n",
        "    grid = GridSearchCV(SVC(probability=True), param_grid, cv=3, n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "    return grid.best_estimator_\n",
        "\n",
        "# Evaluation & Visuals\n",
        "def evaluate_model(y_true, y_pred, y_prob, class_names, title=\"Confusion Matrix\"):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"F1-Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
        "    print(\"ROC-AUC:\", roc_auc_score(y_true, y_prob, multi_class='ovr'))\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sensitivity = np.diag(cm) / np.sum(cm, axis=1)\n",
        "    specificity = [np.sum(np.delete(np.delete(cm, i, axis=0), i, axis=1)) / np.sum(np.delete(cm, i, axis=0)) for i in range(len(class_names))]\n",
        "\n",
        "    for i, cls in enumerate(class_names):\n",
        "        print(f\"{cls} - Sensitivity: {sensitivity[i]:.2f}, Specificity: {specificity[i]:.2f}\")\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot training history\n",
        "def plot_history(history):\n",
        "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title(\"Training History\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Preprocessing & Dataset\n",
        "        images, labels, class_names = preprocess_images(\"dataset/2DSagittal\")\n",
        "        images, labels = balance_data(images, labels)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, stratify=labels, random_state=42)\n",
        "\n",
        "        # DNN Model\n",
        "        model = fine_tune_densenet(num_classes=len(class_names))\n",
        "        model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        history = model.fit(X_train, to_categorical(y_train), validation_data=(X_test, to_categorical(y_test)), epochs=10, batch_size=32)\n",
        "\n",
        "        # Plot training performance\n",
        "        plot_history(history)\n",
        "\n",
        "        # SVM on extracted features\n",
        "        extractor = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
        "        X_train_feat = extractor.predict(X_train)\n",
        "        X_test_feat = extractor.predict(X_test)\n",
        "\n",
        "        best_svm = tune_svm(X_train_feat, y_train)\n",
        "        y_pred_svm = best_svm.predict(X_test_feat)\n",
        "        y_prob_svm = best_svm.predict_proba(X_test_feat)\n",
        "\n",
        "        print(\"\\nSVM Evaluation:\")\n",
        "        evaluate_model(y_test, y_pred_svm, y_prob_svm, class_names)\n",
        "\n",
        "        # Feature Importance (Permutation)\n",
        "        print(\"\\nTop 10 Important Features (SVM):\")\n",
        "        result = permutation_importance(best_svm, X_test_feat, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "        top_features = np.argsort(result.importances_mean)[::-1][:10]\n",
        "        print(\"Feature indices:\", top_features)\n",
        "\n",
        "        # Baseline: Logistic Regression\n",
        "        print(\"\\nBaseline: Logistic Regression\")\n",
        "        X_flat = X_train_feat\n",
        "        clf_lr = LogisticRegression(max_iter=1000)\n",
        "        clf_lr.fit(X_flat, y_train)\n",
        "        y_pred_lr = clf_lr.predict(X_test_feat)\n",
        "        y_prob_lr = clf_lr.predict_proba(X_test_feat)\n",
        "        evaluate_model(y_test, y_pred_lr, y_prob_lr, class_names, title=\"Logistic Regression\")\n",
        "\n",
        "        # Baseline CNN\n",
        "        print(\"\\nBaseline CNN:\")\n",
        "        cnn = simple_cnn((224,224,3), len(class_names))\n",
        "        cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        cnn.fit(X_train, to_categorical(y_train), epochs=5, batch_size=32)\n",
        "        y_pred_cnn = np.argmax(cnn.predict(X_test), axis=1)\n",
        "        y_prob_cnn = cnn.predict(X_test)\n",
        "        evaluate_model(y_test, y_pred_cnn, y_prob_cnn, class_names, title=\"Simple CNN\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47BOfC-2bI8p",
        "outputId": "c28f8be0-08b5-4168-add4-62417873616d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: [Errno 2] No such file or directory: 'dataset/2DSagittal'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save('densenet_finetuned_model.h5')\n",
        "print(\"Model saved successfully as 'densenet_finetuned_model.h5'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "Ibj_w6wm0qYp",
        "outputId": "b3cfea5d-7fca-4a7b-9882-89ac4f5ad1d4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-797656771.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'densenet_finetuned_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model saved successfully as 'densenet_finetuned_model.h5'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# After model.fit(...)\n",
        "history = model.fit(\n",
        "    X_train, to_categorical(y_train),\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, to_categorical(y_test))\n",
        ")\n",
        "\n",
        "# Plot accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy', marker='o')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0.5, 1)  # Set y-axis range\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss', marker='o')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0, 0.5)  # Set y-axis range\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"training_plots.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AnGp4SkkypPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(best_svm, \"svm_model.pkl\")\n",
        "print(\"SVM model saved as 'svm_model.pkl'\")"
      ],
      "metadata": {
        "id": "lcMRrdTf1FE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade joblib scikit-learn"
      ],
      "metadata": {
        "id": "SXcDqBEZ6vLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import joblib # use joblib to load, not pickle\n",
        "\n",
        "# Load fine-tuned DenseNet model\n",
        "densenet_model = load_model('densenet_finetuned_model.h5')\n",
        "\n",
        "# Load trained SVM model\n",
        "# Use joblib.load to load the model since it was saved using joblib.dump\n",
        "with open('svm_model.pkl', 'rb') as f:\n",
        "    svm_model = joblib.load(f)"
      ],
      "metadata": {
        "id": "CX3LP2fZ11O9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def skull_stripping(image):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Apply Otsu's thresholding\n",
        "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Apply morphological operations to remove noise and fill holes\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
        "    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Find contours and keep the largest one (assumed to be brain region)\n",
        "    contours, _ = cv2.findContours(opened, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    mask = np.zeros_like(gray)\n",
        "    if contours:\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        cv2.drawContours(mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
        "\n",
        "    # Mask the original image\n",
        "    brain_only = cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "    return brain_only\n"
      ],
      "metadata": {
        "id": "eSGlAoH18gxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_preprocess_pipeline(image_path):\n",
        "    # Load image\n",
        "    orig = cv2.imread(image_path)\n",
        "    orig_resized = cv2.resize(orig, (224, 224))\n",
        "\n",
        "    # Step 1: Skull stripping\n",
        "    stripped = skull_stripping(orig_resized)\n",
        "\n",
        "    # Step 2: Median filtering\n",
        "    filtered = apply_median_filter(stripped)\n",
        "\n",
        "    # Step 3: To array and preprocessing for DenseNet\n",
        "    img_array = img_to_array(filtered)\n",
        "    img_preprocessed = preprocess_input(img_array)\n",
        "\n",
        "    return orig_resized, stripped, filtered, img_preprocessed\n"
      ],
      "metadata": {
        "id": "kBiaoo4v68l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_and_visualize(image, model, svm, class_names):\n",
        "    pred_probs = model.predict(np.expand_dims(image, axis=0))\n",
        "    pred_class = np.argmax(pred_probs)\n",
        "\n",
        "    # Grad-CAM\n",
        "    cam = generate_grad_cam(model, image, pred_class)\n",
        "    heatmap_img = overlay_heatmap((image + 1) * 127.5, cam)  # Assuming preprocess_input subtracts mean\n",
        "\n",
        "    # Feature extraction\n",
        "    feature_extractor = tf.keras.models.Model(inputs=model.input, outputs=model.layers[-2].output)\n",
        "    features = feature_extractor.predict(np.expand_dims(image, axis=0))\n",
        "\n",
        "    # SVM prediction\n",
        "    svm_pred = svm.predict(features)[0]\n",
        "\n",
        "    return heatmap_img, pred_class, svm_pred\n"
      ],
      "metadata": {
        "id": "ENulRBEv7Am2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_image_pipeline(image_path, model, svm, class_names):\n",
        "    orig, stripped, filtered, preprocessed = full_preprocess_pipeline(image_path)\n",
        "    heatmap_img, cnn_pred, svm_pred = extract_features_and_visualize(preprocessed, model, svm, class_names)\n",
        "\n",
        "    # Plot all stages\n",
        "    titles = [\"Original\", \"Skull Stripped\", \"Median Filtered\", \"Grad-CAM\"]\n",
        "    images = [orig, stripped, filtered, heatmap_img]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for i in range(4):\n",
        "        plt.subplot(1, 4, i+1)\n",
        "        plt.imshow(cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB))\n",
        "        plt.title(titles[i])\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(f\"CNN Predicted: {class_names[cnn_pred]}, SVM Predicted: {class_names[svm_pred]}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "AQgijL_e7Bjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def generate_grad_cam(model, image, class_idx, layer_name=None):\n",
        "    if layer_name is None:\n",
        "        # Try to find the last convolutional layer automatically\n",
        "        for layer in reversed(model.layers):\n",
        "            if 'conv' in layer.name:\n",
        "                layer_name = layer.name\n",
        "                break\n",
        "\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(tf.expand_dims(image, axis=0))\n",
        "        loss = predictions[:, class_idx]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "\n",
        "    # Global average pooling on the gradients\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    conv_outputs = conv_outputs[0]  # Remove batch dimension\n",
        "    cam = np.zeros(conv_outputs.shape[:2], dtype=np.float32)\n",
        "\n",
        "    for i, w in enumerate(pooled_grads):\n",
        "        cam += w * conv_outputs[:, :, i]\n",
        "\n",
        "    cam = np.maximum(cam, 0)  # ReLU\n",
        "    cam = cam / (np.max(cam) + 1e-8)  # Normalize\n",
        "    cam = cv2.resize(cam, (224, 224))  # Resize to image size # Remove .numpy() call as cam is already a NumPy array\n",
        "    return cam"
      ],
      "metadata": {
        "id": "jJtqhZjw7kLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_image_pipeline(\"image_0.jpg\", densenet_model, svm_model, class_names)\n",
        "demo_image_pipeline(\"image_0.jpg\", densenet_model, svm_model, class_names)\n",
        "demo_image_pipeline(\"image_0.jpg\", densenet_model, svm_model, class_names)"
      ],
      "metadata": {
        "id": "55U7l_vJ7D__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tejaswini16256/Brain-Tumor-Detection.git\n",
        "%cd Brain-Tumor-Detection\n"
      ],
      "metadata": {
        "id": "qVek5Qha96eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw5_yyPwAiHk",
        "outputId": "74fd0a89-b148-45c2-c802-aa12cb6f85a8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQxqTVa1DgTX",
        "outputId": "b05cdafa-1a9f-4167-8da5-ae004a20630b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 084RG7JD\n",
            "'10 th marksheet.pdf'\n",
            "'12 th marksheet.pdf'\n",
            " 1A2A5361.JPG\n",
            "'2025_Tejaswini_resume (1) (1) (10).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (11).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (12).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (13).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (14).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (15).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (16).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (17).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (1).pdf'\n",
            "'2025_Tejaswini_resume (1)-1 (1).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (2).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (3).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (4).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (5).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (6).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (7).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (8).pdf'\n",
            "'2025_Tejaswini_resume (1) (1) (9).pdf'\n",
            "'2025_Tejaswini_resume (1)-1.pdf'\n",
            "'2025_Tejaswini_resume (1) (1).pdf'\n",
            "'2025_Tejaswini_resume (1) (2).pdf'\n",
            "'2025_Tejaswini_resume (1) (3).pdf'\n",
            "'2025_Tejaswini_resume (1).pdf'\n",
            "'21610013-assinment finale.docx'\n",
            "'21610013 .pdf'\n",
            " 21610013_tejaswini_resume_IT.pdf\n",
            " 2asiiuos.gdoc\n",
            " 2b.docx\n",
            " 2b.gdoc\n",
            " 2c.docx\n",
            "'40. JS Basics - Class III [HD]'\n",
            " AES.gslides\n",
            " ASSI1C.gdoc\n",
            "'assi1dd (1).gdoc'\n",
            " assi1dd.gdoc\n",
            " assi.1d.gdoc\n",
            " c++\n",
            " certificates_tejashvini.pdf\n",
            " Classroom\n",
            " classs.c\n",
            "'Colab Notebooks'\n",
            "'Contacts-2025-07-27 (2).vcf'\n",
            "'Contacts-2025-07-27 (3).vcf'\n",
            "'Copy of 11a.docx'\n",
            "'Copy of 12b.docx'\n",
            "'Copy of 12c.docx'\n",
            "'Copy of 21610013.gdoc'\n",
            "'Copy of 6a.docx'\n",
            "'Copy of 7a (1).docx'\n",
            "'Copy of 7a.docx'\n",
            "'Copy of 7b.docx'\n",
            "'Copy of 8b (1).docx'\n",
            "'Copy of 8b.docx'\n",
            "'Copy of Copy of UOS Journal.gdoc'\n",
            "'Copy of Project Report TY Mini Project (1).gdoc'\n",
            "'Copy of Project Report TY Mini Project.gdoc'\n",
            "'Copy of WIN_20231221_12_26_01_Pro.mp4'\n",
            " c_programingteju\n",
            "'Cv_tejaswini (1).pdf'\n",
            " Cv_tejaswini.pdf\n",
            " CV_Tejaswini.pdf\n",
            "'CV_Teju (1).pdf'\n",
            " CV_Teju.pdf\n",
            "'DBMS BY RAGHU RAMAKRISHNAN.pdf'\n",
            " Final_Report-6.pdf\n",
            "'hii (1).gsheet'\n",
            " hii.gsheet\n",
            " IMG-20240211-WA0039.jpg\n",
            "'Jogdande_resume_1 (1).pdf'\n",
            "'Jogdande_resume_1 (2).pdf'\n",
            " Jogdande_resume_1.pdf\n",
            "'jogdande_resume_2 (1).pdf'\n",
            "'jogdande_resume_2 (2).pdf'\n",
            "'jogdande_resume_2 (3).pdf'\n",
            "'jogdande_resume_2 (4).pdf'\n",
            "'jogdande_resume_2 (5).pdf'\n",
            "'jogdande_resume_2 (6).pdf'\n",
            " jogdande_resume_2.pdf\n",
            " Jogdande_resume.pdf\n",
            "'Jogdande_Tejaswini_CV (2) (1).pdf'\n",
            "'Jogdande_Tejaswini_CV (2).pdf'\n",
            "'jogdande_Tejaswini_Resume_3 (1) (1) (1).pdf'\n",
            "'jogdande_Tejaswini_Resume_3 (1) (1) (2).pdf'\n",
            "'jogdande_Tejaswini_Resume_3 (1) (1) (3).pdf'\n",
            "'jogdande_Tejaswini_Resume_3 (1) (1) (4).pdf'\n",
            "'jogdande_Tejaswini_Resume_3 (1) (1) (5).pdf'\n",
            "'jogdande_Tejaswini_Resume_3 (1) (1).pdf'\n",
            "'jogdande_Tejaswini_Resume_3 (1).pdf'\n",
            "'jogdande_Tejaswini_Resume_3 (2) (1).pdf'\n",
            "'jogdande_Tejaswini_Resume_3 (2) (2).pdf'\n",
            "'jogdande_Tejaswini_Resume_3 (2).pdf'\n",
            " jogdande_Tejaswini_Resume_3.pdf\n",
            "'Line-1-Model (1).pdf'\n",
            "'mahadbt 2nd year.pdf'\n",
            "'MedGAN images'\n",
            "'Micro Project Report.gdoc'\n",
            " portfolio_Tejashvini.pdf\n",
            "'Report of MiniProject III (1).docx'\n",
            " Resume\n",
            " Resume_Jogdande.pdf\n",
            " Resume_Tejaswini.pdf\n",
            " RESUME_t.pdf\n",
            " Screenshot_2023-02-16-15-28-13-701_com.google.android.apps.nbu.paisa.user.jpg\n",
            "'talent park certificate.pdf'\n",
            "'Tejashvini_IT_CV (1).pdf'\n",
            " Tejashvini_IT_CV.pdf\n",
            " Tejashvini_Jogdande_CV.pdf\n",
            " Tejashvini_Jogdande_Resume.pdf\n",
            " Tejashvini_Photo.JPG\n",
            "'Tejasvini_CV (1).pdf'\n",
            "'Tejasvini_CV (2).pdf'\n",
            "'Tejasvini_CV (3).pdf'\n",
            "'Tejasvini_CV (4).pdf'\n",
            " Tejasvini_CV.pdf\n",
            " Tejasvini_jogdande_2025.pdf\n",
            " Tejasvini_Jogdande_CV.pdf\n",
            " Tejasvini_jogdande.pdf\n",
            "'Tejasvini_Resume_IT (1).pdf'\n",
            "'Tejaswini (1) (1) (1).pdf'\n",
            "'Tejaswini (1) (1) (2).pdf'\n",
            "'Tejaswini (1) (1).pdf'\n",
            "'Tejaswini (1) (2).pdf'\n",
            "'Tejaswini (1) (3).pdf'\n",
            "'tejaswini (1).pdf'\n",
            "'Tejaswini (1).pdf'\n",
            "'tejaswini_2025 (1).pdf'\n",
            "'tejaswini_2025 (2).pdf'\n",
            " tejaswini_2025.pdf\n",
            "'tejaswini (2).pdf'\n",
            "'Tejaswini (2).pdf'\n",
            "'tejaswini (3).pdf'\n",
            "'Tejaswini_CV_2025 (2).pdf'\n",
            "'tejaswini_cv (3).pdf'\n",
            "'TEJASWINI_CV (4) (1).pdf'\n",
            "'TEJASWINI_CV (4) (2).pdf'\n",
            "'TEJASWINI_CV (4) (3).pdf'\n",
            "'TEJASWINI_CV (4) (4).pdf'\n",
            "'TEJASWINI_CV (4).pdf'\n",
            "'Tejaswini_CV (6) (1).pdf'\n",
            "'Tejaswini_CV (6) (2).pdf'\n",
            "'Tejaswini_CV (6).pdf'\n",
            " Tejaswini-CV.pdf\n",
            "'Tejaswini__Jogdande (1) (1).pdf'\n",
            "'Tejaswini__Jogdande (1) (2).pdf'\n",
            "'Tejaswini__Jogdande (1).pdf'\n",
            "'Tejaswini_Jogdande_2025 (1).pdf'\n",
            "'Tejaswini_Jogdande_2025 (2).pdf'\n",
            "'Tejaswini_Jogdande_2025 (3).pdf'\n",
            "'Tejaswini_Jogdande_2025 (4).pdf'\n",
            "'Tejaswini_Jogdande_2025 (5).pdf'\n",
            "'Tejaswini_Jogdande_2025 (6).pdf'\n",
            "'Tejaswini_Jogdande_2025 (7).pdf'\n",
            "'Tejaswini_Jogdande_2025_IT (1) (1).pdf'\n",
            "'Tejaswini_Jogdande_2025_IT (1) (2).pdf'\n",
            "'Tejaswini_Jogdande_2025_IT (1) (3).pdf'\n",
            "'Tejaswini_Jogdande_2025_IT (1) (4).pdf'\n",
            "'Tejaswini_Jogdande_2025_IT (1).pdf'\n",
            " Tejaswini_Jogdande_2025_IT.pdf\n",
            " Tejaswini_Jogdande_2025.pdf\n",
            "'Tejaswini_jogdande (2) (1).pdf'\n",
            "'TEJASWINI JOGDANDE (2) (1).png'\n",
            "'TEJASWINI JOGDANDE (2).png'\n",
            " Tejaswini_Jogdande_CV.pdf\n",
            " Tejaswini_jogdande_resume.pdf\n",
            "'Tejaswini pass photo.jpg'\n",
            " tejaswini.pdf\n",
            "'Tejaswini .pdf'\n",
            " Tejaswini.pdf\n",
            " Tejshvini_UOS.gdoc\n",
            "'tejswini certi of caste.pdf'\n",
            " teju_Cv_2025.pdf\n",
            " Teju_cv_2025.pdf\n",
            " this_message_in_html.html\n",
            "'T_resume (1).pdf'\n",
            "'T_resume (2).pdf'\n",
            "'T_resume (3).pdf'\n",
            "'T_resume (4).pdf'\n",
            "'T_resume (5).pdf'\n",
            "'T_resume (6).pdf'\n",
            "'T_resume (7).pdf'\n",
            " T_resume.pdf\n",
            "'undertaking-ty (1).pdf'\n",
            " undertaking-ty.pdf\n",
            "'Untitled document.gdoc'\n",
            " uos_2b_13.gdoc\n",
            " UOSAssi\n",
            "'validity camp.pdf'\n",
            "'WhatsApp Image 2023-07-21 at 10.03.03 AM.jpeg'\n",
            "'WhatsApp Image 2023-07-21 at 11.13.08 AM.jpeg'\n",
            "'WhatsApp Image 2023-07-21 at 9.39.01 AM (1).jpeg'\n",
            "'WIN_20231221_12_26_01_Pro (1).mp4'\n",
            " WIN_20231221_12_26_01_Pro.mp4\n",
            " WIN_20241015_09_30_31_Pro.mp4\n",
            "'WIN_20241015_09_34_18_Pro (1).mp4'\n",
            " WIN_20241015_09_34_18_Pro.mp4\n",
            " WIN_20250119_11_33_42_Pro.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/Colab Notebooks/*\" \"/content/Brain-Tumor-Detection/\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_rcJS93F9GP",
        "outputId": "1d739921-7a64-44dc-b4b8-0135a4ead2f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/Colab Notebooks/*': No such file or directory\n"
          ]
        }
      ]
    }
  ]
}